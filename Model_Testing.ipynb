{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8cf2990a-9a0e-48f6-b440-8240d45effaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "import numpy as np\n",
    "import urllib.request\n",
    "import cv2\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "db6d25d1-d14b-483b-bfa3-08311a750e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7419aa9-63f9-4db8-ad14-8c7ecc163cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_clf_1 = pkl.load(open('models/model_1.pkl','rb'))\n",
    "model_clf_2 = pkl.load(open('models/model_2.pkl','rb'))\n",
    "model_clf_3 = pkl.load(open('models/model_3.pkl','rb'))\n",
    "model_boost_1 = pkl.load(open('models/model-boost_1.pkl','rb'))\n",
    "model_boost_2 = pkl.load(open('models/model-boost_2.pkl','rb'))\n",
    "\n",
    "pipline1 = pkl.load(open('models/pipline_1.pkl','rb'))\n",
    "labels1 = pkl.load(open('models/labels_1.pkl', 'rb'))\n",
    "pipline2 = pkl.load(open('models/pipline_2.pkl','rb'))\n",
    "labels2 = pkl.load(open('models/labels_2.pkl', 'rb'))\n",
    "pipline3 = pkl.load(open('models/pipline_3.pkl','rb'))\n",
    "labels3 = pkl.load(open('models/labels_3.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "98d4a440-9931-4989-8de2-909a62af6c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "face_cascade = cv2.CascadeClassifier(\"haarcascade_frontalface_default.xml\")\n",
    "def adjusted_detect_face(img):\n",
    "    face_img = img.copy()\n",
    "    face_rect = face_cascade.detectMultiScale(face_img, scaleFactor=1.2, minNeighbors=5)\n",
    "\n",
    "    if len(face_rect) == 0:\n",
    "        return None\n",
    "\n",
    "    x, y, w, h = face_rect[0]\n",
    "    cropped_image = face_img[y:y+h, x:x+w]\n",
    "    return cropped_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b41fc68-af58-4ec7-8355-932e79856894",
   "metadata": {},
   "outputs": [],
   "source": [
    "def url_to_image(url):\n",
    "    # Download the image, convert it to a NumPy array, and then decode it\n",
    "    resp = urllib.request.urlopen(url)\n",
    "    image = np.asarray(bytearray(resp.read()), dtype=\"uint8\")\n",
    "    # Use cv2.imdecode() to convert the array to an OpenCV image format\n",
    "    image = cv2.imdecode(image, cv2.IMREAD_GRAYSCALE) \n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "29c8d1f2-d673-4668-8491-2bb875140d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_url = \"https://img-cdn.inc.com/image/upload/f_webp,c_fit,w_1920,q_auto/images/panoramic/getty_505175324_2000131020009280327_186071.jpg\" # Replace with your image URL\n",
    "image_from_url = url_to_image(image_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8afe3bc2-5b9b-4b1e-9921-b3ebd7f4079a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cropped_face = adjusted_detect_face(image_from_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6e8acb8a-9b60-45f7-8374-8f0b07358d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gray = cv2.cvtColor(cropped_face, cv2.COLOR_BGR2GRAY)\n",
    "resized = cv2.resize(cropped_face, (48, 48))\n",
    "processed = resized.reshape(1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5939bf1b-9e3e-4877-868a-4275c6fa30c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Angry'], dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X1 = pipline1.transform(processed)\n",
    "emotion = model_clf_1.predict(X1)\n",
    "labels1.inverse_transform(emotion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "38cd1966-d988-4137-99a3-3a7296703ce2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Happy'], dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X2 = pipline2.transform(processed)\n",
    "emotion = model_clf_2.predict(X2)\n",
    "labels2.inverse_transform(emotion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ba527fbf-6d69-46e4-b508-ae2e290d3b0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Happy'], dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X3 = pipline3.transform(processed)\n",
    "emotion = model_clf_3.predict(X3)\n",
    "labels3.inverse_transform(emotion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f64b464c-c601-4bff-9cc4-78c881883a95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Happy'], dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emotion = model_boost_1.predict(X1)\n",
    "labels1.inverse_transform(emotion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b057170c-94de-4744-a027-2148eb236f0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Happy'], dtype=object)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emotion = model_boost_2.predict(X2)\n",
    "labels2.inverse_transform(emotion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "04462259-c369-4746-9626-b3e647ed9f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    model_clf_1: [pipline1,labels1],\n",
    "    model_clf_2: [pipline2,labels2],\n",
    "    model_clf_3: [pipline3,labels3],\n",
    "    model_boost_1: [pipline1,labels1],\n",
    "    model_boost_2: [pipline2, labels2]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4b96403f-bee1-4c7d-960b-d34a7111655e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combinepredic(models:dict,img):\n",
    "    pred = []\n",
    "    for model, pipline in models.items():\n",
    "        X = pipline[0].transform(img)\n",
    "        emotion = model.predict(X)\n",
    "        pred.append(pipline[1].inverse_transform(emotion)[0])\n",
    "    return pd.Series(pred).mode()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "eaa53387-9a10-4ce6-8c2c-e163ac5e9c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = combinepredic(models, processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a68bf8e0-0ce4-42de-89d4-505d40befe89",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = [f\"{i}_px\" for i in range(48*48)]\n",
    "value = ['float32']*(48*48)\n",
    "df = pd.read_csv('data.csv',dtype=dict(zip(key,value)))\n",
    "del key, value\n",
    "df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f1af1922-b822-4e56-b7f9-0225a91877e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:,:-1].to_numpy()\n",
    "y = df['emotion'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8cb64364-97e7-4f18-957f-7def5f74e59b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((28669, 2304), (28669,))"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ae3a4c66-2420-4ac9-8e95-25c20f487013",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "56f391e0-1ba7-4f8d-9526-582a5b8824ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5734, 2304)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "68796f31-20de-4466-bdfb-778a483b7081",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5734/5734 [36:28<00:00,  2.62it/s]\n"
     ]
    }
   ],
   "source": [
    "pred = np.zeros((X_test.shape[0],)).astype(np.object_)\n",
    "i = 0\n",
    "for x in tqdm(X_test):\n",
    "    pred[i] = combinepredic(models, x.reshape(1, -1))\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "95414f42-b276-457e-9b71-edce74c7d55f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "de364c0b-faad-4523-907c-015faa2f3a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lab_encoding = LabelEncoder()\n",
    "y_ = lab_encoding.fit_transform(y_test)\n",
    "pred_ = lab_encoding.transform(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "8014d7a2-cca9-4217-b24f-2993db8ad826",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5734,), (5734,))"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_.shape, pred_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "c1cb6633-2466-414a-b132-f62b57df27ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "96c634a1-d8f0-4f75-be3e-e01538fb71eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.93      0.96       961\n",
      "           1       0.99      0.92      0.95       969\n",
      "           2       0.98      0.98      0.98      1883\n",
      "           3       0.90      0.98      0.94      1245\n",
      "           4       0.99      0.98      0.98       676\n",
      "\n",
      "    accuracy                           0.96      5734\n",
      "   macro avg       0.97      0.96      0.96      5734\n",
      "weighted avg       0.96      0.96      0.96      5734\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_,pred_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eaf46c3-cd5f-47ba-8310-fbb85f2ab461",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
